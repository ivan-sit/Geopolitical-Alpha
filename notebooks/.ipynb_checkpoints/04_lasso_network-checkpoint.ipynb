{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAR-Lasso Bipartite Network\n",
    "\n",
    "Run Lasso regression for each energy stock, extract sparse betas, and visualize the commodity → stock network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LassoCV, Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import networkx as nx\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "DATA_PATH = Path(\"../US_CRSP_NYSE/Matrix_Format_SubsetUniverse/\")\n",
    "SECTOR_PATH = Path(\"../US_CRSP_NYSE/Sectors/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load & Prepare Data\n",
    "\n",
    "Same as notebook 02 — load CRSP returns and commodity HAR features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CRSP energy stock returns\n",
    "sectors = pd.read_csv(SECTOR_PATH / \"Sectors_SP500_YahooNWikipedia.csv\")\n",
    "energy_tickers = sectors.loc[sectors['Sector_Wikipedia'] == 'Energy', 'Ticker'].tolist()\n",
    "\n",
    "raw_ret = pd.read_csv(DATA_PATH / \"pvCLCL_20000103_20201231.csv\", index_col=0)\n",
    "ret = raw_ret.T\n",
    "ret.index = pd.to_datetime(ret.index.str.replace('X', ''), format='%Y%m%d')\n",
    "ret.index.name = 'date'\n",
    "\n",
    "energy_avail = [t for t in energy_tickers if t in ret.columns]\n",
    "stock_ret = ret[energy_avail].copy()\n",
    "print(f\"Stock returns: {stock_ret.shape[0]} days × {stock_ret.shape[1]} stocks\")\n",
    "print(f\"Stocks: {energy_avail}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download commodity futures and build HAR features\n",
    "import yfinance as yf\n",
    "\n",
    "COMMODITY_TICKERS = {\n",
    "    'CL=F': 'WTI',\n",
    "    'BZ=F': 'Brent',\n",
    "    'NG=F': 'NatGas',\n",
    "    'HO=F': 'HeatOil',\n",
    "}\n",
    "\n",
    "comm_prices = {}\n",
    "for ticker, name in COMMODITY_TICKERS.items():\n",
    "    df = yf.download(ticker, start='2000-01-01', end='2020-12-31', auto_adjust=True, progress=False)\n",
    "    if len(df) > 0:\n",
    "        if isinstance(df.columns, pd.MultiIndex):\n",
    "            close = df['Close'].iloc[:, 0]\n",
    "        else:\n",
    "            close = df['Close']\n",
    "        comm_prices[name] = close\n",
    "        print(f\"  {name}: {len(close)} rows\")\n",
    "\n",
    "comm_close = pd.DataFrame(comm_prices)\n",
    "comm_close.index = pd.to_datetime(comm_close.index)\n",
    "if comm_close.index.tz is not None:\n",
    "    comm_close.index = comm_close.index.tz_localize(None)\n",
    "comm_close.index.name = 'date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute returns and clip extremes (WTI negative price issue)\n",
    "comm_ret = comm_close.pct_change(fill_method=None).dropna()\n",
    "comm_ret = comm_ret.clip(-1.0, 1.0)\n",
    "\n",
    "# Build HAR features: daily, weekly (5d), monthly (22d) — all lagged by 1\n",
    "har_features = {}\n",
    "for commodity in comm_ret.columns:\n",
    "    r = comm_ret[commodity].dropna()\n",
    "    har_c = pd.DataFrame(index=r.index)\n",
    "    har_c[f'{commodity}_d'] = r.shift(1)\n",
    "    har_c[f'{commodity}_w'] = r.rolling(5).mean().shift(1)\n",
    "    har_c[f'{commodity}_m'] = r.rolling(22).mean().shift(1)\n",
    "    har_features[commodity] = har_c\n",
    "\n",
    "X_har = pd.concat(har_features.values(), axis=1).dropna()\n",
    "print(f\"\\nHAR feature matrix: {X_har.shape[0]} days × {X_har.shape[1]} features\")\n",
    "print(f\"Features: {list(X_har.columns)}\")\n",
    "print(f\"Date range: {X_har.index[0].date()} to {X_har.index[-1].date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align stock returns with HAR features (inner join on dates)\n",
    "common_dates = X_har.index.intersection(stock_ret.index)\n",
    "X = X_har.loc[common_dates].copy()\n",
    "Y = stock_ret.loc[common_dates].copy()\n",
    "\n",
    "print(f\"Aligned data: {len(common_dates)} trading days\")\n",
    "print(f\"X (features): {X.shape}\")\n",
    "print(f\"Y (targets):  {Y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run Lasso Regression for Each Stock\n",
    "\n",
    "We'll use `LassoCV` to automatically select the best λ via cross-validation, then extract the sparse coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features (important for Lasso)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, index=X.index, columns=X.columns)\n",
    "\n",
    "print(\"Features standardized (mean=0, std=1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Lasso for each stock\n",
    "results = {}\n",
    "betas = {}\n",
    "lambdas = {}\n",
    "\n",
    "print(\"Fitting Lasso for each stock (5-fold CV to select λ)...\\n\")\n",
    "\n",
    "for stock in Y.columns:\n",
    "    y = Y[stock].values\n",
    "    \n",
    "    # Drop NaN rows for this stock\n",
    "    mask = ~np.isnan(y)\n",
    "    X_train = X_scaled.values[mask]\n",
    "    y_train = y[mask]\n",
    "    \n",
    "    # LassoCV with 5-fold CV\n",
    "    model = LassoCV(cv=5, max_iter=10000, n_alphas=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Store results\n",
    "    betas[stock] = model.coef_\n",
    "    lambdas[stock] = model.alpha_\n",
    "    results[stock] = model\n",
    "    \n",
    "    n_nonzero = np.sum(model.coef_ != 0)\n",
    "    print(f\"  {stock}: λ = {model.alpha_:.6f}, non-zero β = {n_nonzero}/12, R² = {model.score(X_train, y_train):.4f}\")\n",
    "\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build beta matrix (features × stocks)\n",
    "beta_matrix = pd.DataFrame(betas, index=X.columns)\n",
    "print(f\"Beta matrix shape: {beta_matrix.shape}\")\n",
    "beta_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize the Sparse Beta Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Heatmap with diverging colormap\n",
    "vmax = np.abs(beta_matrix.values).max()\n",
    "sns.heatmap(beta_matrix, cmap='RdBu_r', center=0, vmin=-vmax, vmax=vmax,\n",
    "            annot=True, fmt='.3f', ax=ax, annot_kws={'size': 8},\n",
    "            linewidths=0.5, cbar_kws={'label': 'β coefficient'})\n",
    "\n",
    "# Group separators for commodities\n",
    "for y in [3, 6, 9]:\n",
    "    ax.axhline(y, color='black', linewidth=2)\n",
    "\n",
    "ax.set_title('Lasso Coefficients: Commodity HAR Features → Energy Stocks\\n(non-zero = edge in bipartite graph)',\n",
    "             fontsize=13, fontweight='bold')\n",
    "ax.set_ylabel('HAR Feature')\n",
    "ax.set_xlabel('Stock')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Sparsity stats\n",
    "total_params = beta_matrix.size\n",
    "nonzero_params = (beta_matrix != 0).sum().sum()\n",
    "print(f\"Sparsity: {nonzero_params}/{total_params} non-zero ({100*nonzero_params/total_params:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build & Visualize the Bipartite Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bipartite_graph(beta_matrix, threshold=0.0):\n",
    "    \"\"\"\n",
    "    Build a bipartite graph from the beta matrix.\n",
    "    \n",
    "    Nodes:\n",
    "      - Commodity nodes (left): WTI, Brent, NatGas, HeatOil\n",
    "      - Stock nodes (right): 14 energy stocks\n",
    "    \n",
    "    Edges:\n",
    "      - Draw edge from commodity c to stock s if any of the 3 horizon betas are non-zero\n",
    "      - Edge weight = sum of absolute betas for that commodity-stock pair\n",
    "      - Edge attributes store which horizon(s) are active\n",
    "    \"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add commodity nodes\n",
    "    commodities = ['WTI', 'Brent', 'NatGas', 'HeatOil']\n",
    "    for c in commodities:\n",
    "        G.add_node(c, bipartite=0, node_type='commodity')\n",
    "    \n",
    "    # Add stock nodes\n",
    "    stocks = beta_matrix.columns.tolist()\n",
    "    for s in stocks:\n",
    "        G.add_node(s, bipartite=1, node_type='stock')\n",
    "    \n",
    "    # Add edges based on non-zero betas\n",
    "    horizons = ['d', 'w', 'm']\n",
    "    horizon_names = {'d': 'daily', 'w': 'weekly', 'm': 'monthly'}\n",
    "    \n",
    "    for commodity in commodities:\n",
    "        for stock in stocks:\n",
    "            # Get the 3 betas for this commodity-stock pair\n",
    "            beta_d = beta_matrix.loc[f'{commodity}_d', stock]\n",
    "            beta_w = beta_matrix.loc[f'{commodity}_w', stock]\n",
    "            beta_m = beta_matrix.loc[f'{commodity}_m', stock]\n",
    "            \n",
    "            betas = {'d': beta_d, 'w': beta_w, 'm': beta_m}\n",
    "            active = {h: b for h, b in betas.items() if abs(b) > threshold}\n",
    "            \n",
    "            if active:\n",
    "                weight = sum(abs(b) for b in active.values())\n",
    "                dominant = max(active.keys(), key=lambda h: abs(active[h]))\n",
    "                G.add_edge(commodity, stock, \n",
    "                          weight=weight,\n",
    "                          betas=betas,\n",
    "                          active_horizons=list(active.keys()),\n",
    "                          dominant_horizon=dominant)\n",
    "    \n",
    "    return G\n",
    "\n",
    "G = build_bipartite_graph(beta_matrix)\n",
    "print(f\"Bipartite graph: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
    "print(f\"  Commodity nodes: {[n for n, d in G.nodes(data=True) if d.get('node_type') == 'commodity']}\")\n",
    "print(f\"  Stock nodes: {[n for n, d in G.nodes(data=True) if d.get('node_type') == 'stock']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_bipartite_graph(G, figsize=(16, 10)):\n",
    "    \"\"\"Visualize the bipartite commodity → stock graph.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Separate node types\n",
    "    commodities = [n for n, d in G.nodes(data=True) if d.get('node_type') == 'commodity']\n",
    "    stocks = [n for n, d in G.nodes(data=True) if d.get('node_type') == 'stock']\n",
    "    \n",
    "    # Position nodes: commodities on left, stocks on right\n",
    "    pos = {}\n",
    "    for i, c in enumerate(commodities):\n",
    "        pos[c] = (0, len(commodities) - 1 - i)\n",
    "    for i, s in enumerate(stocks):\n",
    "        pos[s] = (2, len(stocks) - 1 - i)\n",
    "    \n",
    "    # Normalize positions\n",
    "    max_y = max(len(commodities), len(stocks))\n",
    "    for node in pos:\n",
    "        x, y = pos[node]\n",
    "        pos[node] = (x, y * max_y / (len(stocks) if x == 2 else len(commodities)))\n",
    "    \n",
    "    # Colors for horizons\n",
    "    horizon_colors = {'d': '#E74C3C', 'w': '#3498DB', 'm': '#2ECC71'}\n",
    "    \n",
    "    # Draw edges\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        color = horizon_colors.get(data.get('dominant_horizon', 'd'), 'gray')\n",
    "        weight = data.get('weight', 0.1)\n",
    "        width = 0.5 + weight * 30  # Scale for visibility\n",
    "        ax.annotate('', xy=pos[v], xytext=pos[u],\n",
    "                   arrowprops=dict(arrowstyle='->', color=color, lw=width, alpha=0.6,\n",
    "                                  connectionstyle='arc3,rad=0.1'))\n",
    "    \n",
    "    # Draw commodity nodes\n",
    "    comm_colors = {'WTI': '#2C3E50', 'Brent': '#2980B9', 'NatGas': '#E67E22', 'HeatOil': '#27AE60'}\n",
    "    for c in commodities:\n",
    "        x, y = pos[c]\n",
    "        circle = plt.Circle((x, y), 0.3, color=comm_colors.get(c, 'gray'), ec='black', lw=2, zorder=5)\n",
    "        ax.add_patch(circle)\n",
    "        ax.text(x - 0.5, y, c, ha='right', va='center', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # Draw stock nodes\n",
    "    for s in stocks:\n",
    "        x, y = pos[s]\n",
    "        out_degree = G.in_degree(s)  # edges coming into this stock\n",
    "        size = 0.2 + out_degree * 0.05\n",
    "        circle = plt.Circle((x, y), size, color='#E74C3C', ec='black', lw=1.5, zorder=5)\n",
    "        ax.add_patch(circle)\n",
    "        ax.text(x + 0.4, y, s, ha='left', va='center', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    # Legend\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [\n",
    "        Patch(facecolor='#E74C3C', label='Daily dominates'),\n",
    "        Patch(facecolor='#3498DB', label='Weekly dominates'),\n",
    "        Patch(facecolor='#2ECC71', label='Monthly dominates'),\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='lower center', ncol=3, fontsize=10, framealpha=0.9)\n",
    "    \n",
    "    ax.set_xlim(-1, 3.5)\n",
    "    ax.set_ylim(-1, max_y + 1)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.axis('off')\n",
    "    ax.set_title('Bipartite Network: Commodity → Stock Predictive Links\\n(edge color = dominant HAR horizon, width = |β| magnitude)',\n",
    "                fontsize=13, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_bipartite_graph(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Network Statistics & Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Degree analysis: which commodities predict the most stocks?\n",
    "commodities = ['WTI', 'Brent', 'NatGas', 'HeatOil']\n",
    "stocks = [n for n, d in G.nodes(data=True) if d.get('node_type') == 'stock']\n",
    "\n",
    "print(\"COMMODITY OUT-DEGREE (# stocks each commodity predicts):\")\n",
    "for c in commodities:\n",
    "    out_deg = G.out_degree(c)\n",
    "    print(f\"  {c}: {out_deg} stocks\")\n",
    "\n",
    "print(\"\\nSTOCK IN-DEGREE (# commodities predicting each stock):\")\n",
    "stock_degrees = [(s, G.in_degree(s)) for s in stocks]\n",
    "stock_degrees.sort(key=lambda x: x[1], reverse=True)\n",
    "for s, deg in stock_degrees:\n",
    "    print(f\"  {s}: {deg} commodities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which horizon dominates across all edges?\n",
    "horizon_counts = {'d': 0, 'w': 0, 'm': 0}\n",
    "for u, v, data in G.edges(data=True):\n",
    "    for h in data.get('active_horizons', []):\n",
    "        horizon_counts[h] += 1\n",
    "\n",
    "print(\"ACTIVE HORIZON COUNTS (across all edges):\")\n",
    "print(f\"  Daily:   {horizon_counts['d']}\")\n",
    "print(f\"  Weekly:  {horizon_counts['w']}\")\n",
    "print(f\"  Monthly: {horizon_counts['m']}\")\n",
    "\n",
    "# Dominant horizon distribution\n",
    "dominant_counts = {'d': 0, 'w': 0, 'm': 0}\n",
    "for u, v, data in G.edges(data=True):\n",
    "    dom = data.get('dominant_horizon')\n",
    "    if dom:\n",
    "        dominant_counts[dom] += 1\n",
    "\n",
    "print(\"\\nDOMINANT HORIZON (per edge):\")\n",
    "print(f\"  Daily:   {dominant_counts['d']}\")\n",
    "print(f\"  Weekly:  {dominant_counts['w']}\")\n",
    "print(f\"  Monthly: {dominant_counts['m']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 strongest edges\n",
    "edges_list = []\n",
    "for u, v, data in G.edges(data=True):\n",
    "    edges_list.append({\n",
    "        'commodity': u,\n",
    "        'stock': v,\n",
    "        'weight': data['weight'],\n",
    "        'dominant': data['dominant_horizon'],\n",
    "        'beta_d': data['betas']['d'],\n",
    "        'beta_w': data['betas']['w'],\n",
    "        'beta_m': data['betas']['m'],\n",
    "    })\n",
    "\n",
    "edges_df = pd.DataFrame(edges_list).sort_values('weight', ascending=False)\n",
    "print(\"TOP 10 STRONGEST EDGES (by |β| weight):\")\n",
    "edges_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Importance Aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average absolute beta per feature (across all stocks)\n",
    "feature_importance = beta_matrix.abs().mean(axis=1).sort_values(ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "colors = ['#2C3E50' if 'WTI' in f else '#2980B9' if 'Brent' in f else '#E67E22' if 'NatGas' in f else '#27AE60'\n",
    "          for f in feature_importance.index]\n",
    "feature_importance.plot.barh(ax=ax, color=colors)\n",
    "ax.set_xlabel('Mean |β| across stocks')\n",
    "ax.set_title('Feature Importance: Which HAR Features Are Most Predictive?', fontsize=12, fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(feature_importance.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compute Residuals (for Strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predictions and residuals for each stock\n",
    "predictions = pd.DataFrame(index=X.index, columns=Y.columns)\n",
    "residuals = pd.DataFrame(index=X.index, columns=Y.columns)\n",
    "\n",
    "for stock in Y.columns:\n",
    "    model = results[stock]\n",
    "    y_pred = model.predict(X_scaled.values)\n",
    "    predictions[stock] = y_pred\n",
    "    residuals[stock] = Y[stock].values - y_pred\n",
    "\n",
    "print(f\"Predictions shape: {predictions.shape}\")\n",
    "print(f\"Residuals shape: {residuals.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "\n",
    "# Sample 4 stocks\n",
    "sample_stocks = ['XOM', 'SLB', 'EOG', 'VLO']\n",
    "for ax, stock in zip(axes.flat, sample_stocks):\n",
    "    res = residuals[stock].dropna()\n",
    "    ax.hist(res, bins=50, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "    ax.axvline(0, color='red', linestyle='--', linewidth=1)\n",
    "    ax.set_title(f'{stock} Residuals (mean={res.mean():.5f}, std={res.std():.4f})')\n",
    "    ax.set_xlabel('Residual')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "plt.suptitle('Residual Distributions: ε = r - r̂', fontsize=13, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative residuals over time (should be mean-zero if model is unbiased)\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "\n",
    "for stock in sample_stocks:\n",
    "    cum_res = residuals[stock].dropna().cumsum()\n",
    "    ax.plot(cum_res, label=stock, linewidth=0.8)\n",
    "\n",
    "ax.axhline(0, color='black', linestyle='--', linewidth=0.5)\n",
    "ax.set_title('Cumulative Residuals Over Time', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Cumulative ε')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"HAR-LASSO BIPARTITE NETWORK SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nData:\")\n",
    "print(f\"  Trading days: {len(common_dates)}\")\n",
    "print(f\"  Stocks: {len(stocks)}\")\n",
    "print(f\"  Commodities: {len(commodities)}\")\n",
    "print(f\"  HAR features: {X.shape[1]} (4 commodities × 3 horizons)\")\n",
    "\n",
    "print(f\"\\nLasso Results:\")\n",
    "print(f\"  Total parameters: {beta_matrix.size}\")\n",
    "print(f\"  Non-zero: {(beta_matrix != 0).sum().sum()} ({100*(beta_matrix != 0).sum().sum()/beta_matrix.size:.1f}%)\")\n",
    "print(f\"  Avg R² across stocks: {np.mean([results[s].score(X_scaled.values[~np.isnan(Y[s].values)], Y[s].values[~np.isnan(Y[s].values)]) for s in Y.columns]):.4f}\")\n",
    "\n",
    "print(f\"\\nBipartite Graph:\")\n",
    "print(f\"  Nodes: {G.number_of_nodes()} ({len(commodities)} commodities + {len(stocks)} stocks)\")\n",
    "print(f\"  Edges: {G.number_of_edges()} predictive links\")\n",
    "print(f\"  Density: {G.number_of_edges() / (len(commodities) * len(stocks)):.2%}\")\n",
    "\n",
    "print(f\"\\nDominant Horizon: {max(dominant_counts.keys(), key=lambda k: dominant_counts[k])}\")\n",
    "print(f\"  Daily: {dominant_counts['d']}, Weekly: {dominant_counts['w']}, Monthly: {dominant_counts['m']}\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
