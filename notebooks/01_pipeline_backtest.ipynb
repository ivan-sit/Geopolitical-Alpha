{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md-title",
   "metadata": {},
   "source": [
    "# Geopolitical Alpha: HAR-Lasso Bipartite Network — Full Pipeline\n",
    "\n",
    "**Math 279 — Ivan Sit**\n",
    "\n",
    "This notebook runs the complete pipeline end-to-end:\n",
    "\n",
    "1. **Data Loading** — CRSP energy stocks + commodity futures + SPY\n",
    "2. **Feature Engineering** — HAR (daily/weekly/monthly) + derived cross-commodity features\n",
    "3. **Market Residualization** — rolling-beta OLS to strip SPY co-movement\n",
    "4. **LassoCV Rolling OOS** — dynamic penalty selection, no look-ahead, bipartite edge extraction\n",
    "5. **Bipartite Network** — which commodities predict which stocks\n",
    "6. **Backtest** — cross-sectional long/short, 5 bps TC, rolling Sharpe\n",
    "7. **Sensitivity** — window length (60 / 126 / 252 d) and target (Y_idio vs Y_raw)\n",
    "\n",
    "**Key fix vs earlier version**: `LassoCV` with `TimeSeriesSplit` dynamically selects the penalty\n",
    "inside each rolling window — no fixed `alpha=0.001`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, warnings\n",
    "sys.path.insert(0, '..')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.linear_model import LassoCV, Lasso\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from src.pipeline import load_all\n",
    "from src.strategy.backtest import compute_metrics, rolling_sharpe\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'figure.dpi': 110,\n",
    "    'axes.spines.top': False,\n",
    "    'axes.spines.right': False,\n",
    "    'font.size': 11,\n",
    "})\n",
    "SEED = 42\n",
    "OUTPUTS = Path('../outputs')\n",
    "OUTPUTS.mkdir(exist_ok=True)\n",
    "print('Libraries loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-s1",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1 — Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_all(\n",
    "    source='cache',\n",
    "    start='2000-01-01',\n",
    "    end='2024-12-31',\n",
    "    sector='energy',\n",
    "    beta_window=252,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "X            = data['X']           # feature matrix  (T × P)\n",
    "Y_idio       = data['Y_idio']      # idiosyncratic returns  (T × N)\n",
    "Y_raw        = data['Y_raw']       # raw stock returns  (T × N)\n",
    "spy_ret      = data['spy_ret']     # SPY daily returns  (T,)\n",
    "comm_prices  = data['comm_prices'] # commodity prices aligned to equity calendar\n",
    "\n",
    "print(f'\\n{\" Data dimensions \":=^60}')\n",
    "print(f'  Feature matrix X    : {X.shape[0]:>6} days  ×  {X.shape[1]:>3} features')\n",
    "print(f'  Y_idio              : {Y_idio.shape[0]:>6} days  ×  {Y_idio.shape[1]:>3} stocks')\n",
    "print(f'  Y_raw               : {Y_raw.shape[0]:>6} days  ×  {Y_raw.shape[1]:>3} stocks')\n",
    "print(f'  Date range          : {X.index[0].date()} → {X.index[-1].date()}')\n",
    "print(f'  Features            : {list(X.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-overview",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Commodity prices overview ─────────────────────────────────────────────────\n",
    "comm_ret = comm_prices.pct_change(fill_method=None).clip(-1, 1)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 8))\n",
    "for ax, col in zip(axes.flat, comm_prices.columns):\n",
    "    (comm_prices[col] / comm_prices[col].iloc[0]).plot(ax=ax, linewidth=1.2, color='steelblue')\n",
    "    ax.set_title(f'{col} — normalised price (base=1)', fontweight='bold')\n",
    "    ax.set_ylabel('Relative price')\n",
    "\n",
    "    # Mark key geopolitical events\n",
    "    events = {\n",
    "        'Libya 2011': '2011-02-17',\n",
    "        'OPEC war 2014': '2014-11-27',\n",
    "        'COVID 2020': '2020-03-09',\n",
    "        'Ukraine 2022': '2022-02-24',\n",
    "    }\n",
    "    for label, date in events.items():\n",
    "        dt = pd.Timestamp(date)\n",
    "        if ax.get_xlim()[0] < mdates.date2num(dt) < ax.get_xlim()[1]:\n",
    "            ax.axvline(dt, color='red', linestyle=':', linewidth=1, alpha=0.7)\n",
    "\n",
    "plt.suptitle('Commodity prices — normalised (red lines = key geopolitical events)',\n",
    "             fontsize=13, fontweight='bold', y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-s2",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2 — Feature Engineering\n",
    "\n",
    "The HAR feature matrix $X \\in \\mathbb{R}^{T \\times P}$ is built from commodity prices:\n",
    "\n",
    "$$\n",
    "X_t = \\bigl[\n",
    "  r^{(d)}_{t-1},\\; \\bar{r}^{(w)}_{t-5:t-1},\\; \\bar{r}^{(m)}_{t-22:t-1},\\;\n",
    "  \\text{CrackSpread},\\; \\text{OilGasRatio},\\; \\text{RV},\\; \\text{BrentWTI},\\; \\ldots\n",
    "\\bigr]\n",
    "$$\n",
    "\n",
    "All features are **lagged by at least 1 day** — no look-ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature-overview",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Feature correlation heatmap ───────────────────────────────────────────────\n",
    "fig, ax = plt.subplots(figsize=(14, 11))\n",
    "corr = X.corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "sns.heatmap(corr, mask=mask, cmap='RdBu_r', center=0, vmin=-1, vmax=1,\n",
    "            annot=False, linewidths=0.3, ax=ax)\n",
    "ax.set_title(f'Feature Correlation Matrix  ({X.shape[1]} features × {X.shape[1]} features)',\n",
    "             fontweight='bold', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Feature statistics:')\n",
    "print(X.describe().T[['mean','std','min','max']].round(5).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature-time",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── WTI HAR features over time ────────────────────────────────────────────────\n",
    "wti_cols = [c for c in X.columns if c.startswith('WTI_d') or c.startswith('WTI_w') or c.startswith('WTI_m')]\n",
    "fig, axes = plt.subplots(3, 1, figsize=(16, 9), sharex=True)\n",
    "labels = ['Daily lag (t−1)', '5-day mean (t−5:t−1)', '22-day mean (t−22:t−1)']\n",
    "colors = ['steelblue', 'darkorange', 'seagreen']\n",
    "for ax, col, label, color in zip(axes, wti_cols[:3], labels, colors):\n",
    "    ax.plot(X[col], linewidth=0.8, color=color, alpha=0.85)\n",
    "    ax.set_ylabel(label, fontsize=10)\n",
    "    ax.axhline(0, color='black', linewidth=0.5)\n",
    "    for date in ['2011-02-17','2014-11-27','2020-03-09','2022-02-24']:\n",
    "        ax.axvline(pd.Timestamp(date), color='red', linestyle=':', linewidth=1, alpha=0.6)\n",
    "\n",
    "axes[0].set_title('WTI HAR features over time  (red = geopolitical events)', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-s3",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3 — Market Residualization\n",
    "\n",
    "We strip the systematic market factor using rolling-window OLS beta:\n",
    "\n",
    "$$\n",
    "Y^{\\text{idio}}_t = r^{\\text{stock}}_t - \\hat{\\beta}_t \\cdot r^{\\text{SPY}}_t,\n",
    "\\qquad\n",
    "\\hat{\\beta}_t = \\frac{\\text{Cov}(r^{\\text{stock}}, r^{\\text{SPY}})_{252d}}{\\text{Var}(r^{\\text{SPY}})_{252d}}\n",
    "$$\n",
    "\n",
    "This isolates the **commodity-specific** alpha from broad market moves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Show residualization effect for XOM and one small-cap ─────────────────────\n",
    "sample_stocks = [s for s in ['XOM', 'DVN', 'HAL', 'RRC'] if s in Y_raw.columns]\n",
    "\n",
    "fig, axes = plt.subplots(len(sample_stocks), 2, figsize=(16, 3.5 * len(sample_stocks)))\n",
    "\n",
    "for row, ticker in enumerate(sample_stocks):\n",
    "    ax_raw, ax_idio = axes[row]\n",
    "\n",
    "    r = Y_raw[ticker].dropna()\n",
    "    i = Y_idio[ticker].dropna()\n",
    "    common_idx = r.index.intersection(i.index)\n",
    "\n",
    "    ax_raw.plot(r.loc[common_idx].rolling(21).mean(), color='steelblue', linewidth=1.2)\n",
    "    ax_raw.set_title(f'{ticker} — Raw return (21d MA)', fontweight='bold')\n",
    "    ax_raw.axhline(0, color='black', linewidth=0.5)\n",
    "\n",
    "    ax_idio.plot(i.loc[common_idx].rolling(21).mean(), color='darkorange', linewidth=1.2)\n",
    "    ax_idio.set_title(f'{ticker} — Idiosyncratic return (21d MA)', fontweight='bold')\n",
    "    ax_idio.axhline(0, color='black', linewidth=0.5)\n",
    "\n",
    "    # Annotate correlation with SPY\n",
    "    spy_common = spy_ret.reindex(common_idx).dropna()\n",
    "    r_spy = r.reindex(spy_common.index)\n",
    "    i_spy = i.reindex(spy_common.index)\n",
    "    corr_raw  = r_spy.corr(spy_common)\n",
    "    corr_idio = i_spy.corr(spy_common)\n",
    "    ax_raw.set_xlabel(f'Corr(raw, SPY) = {corr_raw:.3f}')\n",
    "    ax_idio.set_xlabel(f'Corr(idio, SPY) = {corr_idio:.3f}  ← should be ≈0')\n",
    "\n",
    "plt.suptitle('Market Residualization: Raw vs Idiosyncratic Returns', fontsize=13, fontweight='bold', y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-s4",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4 — LassoCV Rolling Out-of-Sample\n",
    "\n",
    "**Core algorithm — strictly causal:**\n",
    "\n",
    "```\n",
    "For each rebalance day t (every Friday):\n",
    "  1. Take training slice: X[t-W:t], Y[t-W:t]  (past W days only)\n",
    "  2. Standardize X on training data: z = (x - μ_train) / σ_train\n",
    "  3. Fit LassoCV with TimeSeriesSplit(n_splits=3) to find optimal α\n",
    "  4. Predict: ŷ_t = model.predict(z_t)   (next-day prediction)\n",
    "  5. Store: prediction, selected α, non-zero coefficients (→ bipartite edges)\n",
    "```\n",
    "\n",
    "**Why LassoCV over fixed α**: volatility regimes shift — a fixed penalty that works during low-vol\n",
    "will under-regularize during high-vol crises and over-regularize during calm periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-filter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Liquid universe filter ────────────────────────────────────────────────────\n",
    "# Keep stocks with ≥70% non-NaN observations over the full period.\n",
    "# Sparse stocks are mostly micro-caps with very short listing windows.\n",
    "coverage = Y_raw.notna().mean()\n",
    "COVERAGE_THR = 0.70\n",
    "liquid = coverage[coverage >= COVERAGE_THR].index.tolist()\n",
    "\n",
    "print(f'Full universe : {Y_raw.shape[1]} stocks')\n",
    "print(f'Liquid (≥{COVERAGE_THR:.0%}): {len(liquid)} stocks')\n",
    "print(f'Dropped       : {Y_raw.shape[1] - len(liquid)} stocks')\n",
    "\n",
    "Y_raw_liq  = Y_raw[liquid]\n",
    "Y_idio_liq = Y_idio[liquid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasso-cv-fn",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHAS = np.logspace(-4, -0.5, 15)   # 15 candidates from 0.0001 to ~0.32\n",
    "TSCV   = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "def rolling_lasso_cv(\n",
    "    X: pd.DataFrame,\n",
    "    Y: pd.DataFrame,\n",
    "    train_window: int = 252,\n",
    "    weekly: bool = True,\n",
    "    min_obs: int = 60,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Rolling OOS LassoCV — strictly causal, bipartite edge extraction.\n",
    "\n",
    "    Returns dict with:\n",
    "        'predictions' : DataFrame (T × N)  — OOS predicted returns\n",
    "        'alpha_hist'  : DataFrame (T × N)  — CV-selected alpha per stock per date\n",
    "        'edges'       : list of (date, feature, stock, coef) tuples\n",
    "        'sparsity'    : Series  — daily fraction of non-zero coefs (averaged across stocks)\n",
    "    \"\"\"\n",
    "    n, feat_names = len(X), list(X.columns)\n",
    "    predictions = pd.DataFrame(np.nan, index=X.index, columns=Y.columns)\n",
    "    alpha_hist  = pd.DataFrame(np.nan, index=X.index, columns=Y.columns)\n",
    "    edges_list  = []\n",
    "    sparsity    = pd.Series(np.nan, index=X.index)\n",
    "\n",
    "    # Which days to rebalance\n",
    "    if weekly:\n",
    "        trade_idx = [t for t in range(train_window, n) if X.index[t].weekday() == 4]\n",
    "    else:\n",
    "        trade_idx = list(range(train_window, n))\n",
    "\n",
    "    print(f'LassoCV rolling OOS — window={train_window}d, '\n",
    "          f'{\"weekly\" if weekly else \"daily\"}, {len(trade_idx)} rebalances')\n",
    "    print(f'Universe: {Y.shape[1]} stocks | α candidates: {len(ALPHAS)}')\n",
    "\n",
    "    X_arr = X.values\n",
    "\n",
    "    for i, t in enumerate(trade_idx):\n",
    "        if i % 100 == 0:\n",
    "            print(f'  [{i+1:4d}/{len(trade_idx)}]  {X.index[t].date()} ...', end='\\r')\n",
    "\n",
    "        X_tr = X_arr[t - train_window : t]\n",
    "        X_te = X_arr[t : t + 1]\n",
    "        mu, sd = X_tr.mean(0), X_tr.std(0) + 1e-8\n",
    "        X_tr_z = (X_tr - mu) / sd\n",
    "        X_te_z = (X_te - mu) / sd\n",
    "\n",
    "        date       = X.index[t]\n",
    "        nnz_counts = []\n",
    "\n",
    "        for stock in Y.columns:\n",
    "            y_tr = Y[stock].iloc[t - train_window : t].values\n",
    "            mask = ~np.isnan(y_tr)\n",
    "            if mask.sum() < min_obs:\n",
    "                continue\n",
    "\n",
    "            model = LassoCV(\n",
    "                alphas=ALPHAS, cv=TSCV,\n",
    "                max_iter=3000, fit_intercept=True, n_jobs=1,\n",
    "            )\n",
    "            model.fit(X_tr_z[mask], y_tr[mask])\n",
    "\n",
    "            predictions.loc[date, stock]  = float(model.predict(X_te_z)[0])\n",
    "            alpha_hist.loc[date, stock]   = model.alpha_\n",
    "            nnz = np.where(model.coef_ != 0)[0]\n",
    "            nnz_counts.append(len(nnz) / len(feat_names))\n",
    "\n",
    "            for fi in nnz:\n",
    "                edges_list.append((date, feat_names[fi], stock, float(model.coef_[fi])))\n",
    "\n",
    "        if nnz_counts:\n",
    "            sparsity.loc[date] = float(np.mean(nnz_counts))\n",
    "\n",
    "    print(f'\\nDone! {predictions.notna().any(axis=1).sum()} prediction days, '\n",
    "          f'{len(edges_list)} total edges.')\n",
    "    return dict(\n",
    "        predictions=predictions,\n",
    "        alpha_hist=alpha_hist,\n",
    "        edges=edges_list,\n",
    "        sparsity=sparsity,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-lasso-cv",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Run LassoCV on idiosyncratic returns (252-day window) ─────────────────────\n",
    "# Runtime: ~5-10 min depending on CPU (weekly rebalancing × liquid universe)\n",
    "result_252 = rolling_lasso_cv(X, Y_idio_liq, train_window=252, weekly=True)\n",
    "\n",
    "preds_252   = result_252['predictions']\n",
    "alpha_hist  = result_252['alpha_hist']\n",
    "edges_list  = result_252['edges']\n",
    "sparsity    = result_252['sparsity']\n",
    "\n",
    "# Save for use in notebook 02\n",
    "preds_252.to_pickle(OUTPUTS / 'preds_252.pkl')\n",
    "pd.DataFrame(edges_list, columns=['date','feature','stock','coef']).to_pickle(OUTPUTS / 'edges_252.pkl')\n",
    "print('Saved predictions and edges to outputs/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-s5",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5 — Feature Sparsity & Alpha Diagnostics\n",
    "\n",
    "Before running the backtest, verify the model is actually finding signal — not zeroing everything out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sparsity-diag",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Sparsity and alpha evolution over time ────────────────────────────────────\n",
    "sp = sparsity.dropna()\n",
    "alpha_med = alpha_hist.median(axis=1).dropna()\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 8), sharex=True)\n",
    "\n",
    "ax = axes[0]\n",
    "ax.plot(sp.rolling(13).mean(), color='steelblue', linewidth=1.5,\n",
    "        label='Feature density (13-wk MA)')\n",
    "ax.fill_between(sp.index, sp.rolling(13).mean(), alpha=0.15, color='steelblue')\n",
    "ax.set_ylabel('Fraction of non-zero coefficients')\n",
    "ax.set_title('Model sparsity over time  (higher = more features active)', fontweight='bold')\n",
    "ax.legend()\n",
    "for date in ['2011-02-17','2014-11-27','2020-03-09','2022-02-24']:\n",
    "    ax.axvline(pd.Timestamp(date), color='red', linestyle=':', linewidth=1, alpha=0.7)\n",
    "\n",
    "ax = axes[1]\n",
    "ax.semilogy(alpha_med.rolling(13).mean(), color='darkorange', linewidth=1.5,\n",
    "            label='Median CV-selected alpha (13-wk MA)')\n",
    "ax.set_ylabel('Lasso alpha (log scale)')\n",
    "ax.set_title('CV-selected penalty α over time  (higher α = more regularization)', fontweight='bold')\n",
    "ax.legend()\n",
    "for date in ['2011-02-17','2014-11-27','2020-03-09','2022-02-24']:\n",
    "    ax.axvline(pd.Timestamp(date), color='red', linestyle=':', linewidth=1, alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Average feature density : {sp.mean():.1%}  (fraction of features with non-zero coef)')\n",
    "print(f'Average selected alpha  : {alpha_med.mean():.5f}')\n",
    "print(f'Min / max selected alpha: {alpha_med.min():.5f} / {alpha_med.max():.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Which features are selected most often? ───────────────────────────────────\n",
    "if edges_list:\n",
    "    edges_df = pd.DataFrame(edges_list, columns=['date','feature','stock','coef'])\n",
    "    feat_usage = edges_df['feature'].value_counts(normalize=True)\n",
    "    feat_sign  = edges_df.groupby('feature')['coef'].mean()  # avg direction\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    feat_usage.head(20).sort_values().plot.barh(\n",
    "        ax=axes[0], color='steelblue')\n",
    "    axes[0].set_title('Top 20 most-selected features (% of all edges)', fontweight='bold')\n",
    "    axes[0].set_xlabel('Selection frequency')\n",
    "\n",
    "    feat_sign.reindex(feat_usage.head(20).index).sort_values().plot.barh(\n",
    "        ax=axes[1], color=['crimson' if v < 0 else 'seagreen' for v in feat_sign.reindex(feat_usage.head(20).index).sort_values()])\n",
    "    axes[1].axvline(0, color='black', linewidth=0.8)\n",
    "    axes[1].set_title('Mean coefficient sign  (green=positive, red=negative)', fontweight='bold')\n",
    "    axes[1].set_xlabel('Mean Lasso coefficient')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No edges found — model zeroed all coefficients. Try a smaller alpha.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-s6",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 6 — Bipartite Network Extraction\n",
    "\n",
    "The **core contribution** of this project: non-zero Lasso coefficients define a bipartite graph\n",
    "$G = (U \\cup V, E)$ where:\n",
    "- $U$ = commodity features (27 nodes)\n",
    "- $V$ = energy stocks ($N$ nodes)\n",
    "- $E$ = non-zero coefficients at time $t$  (edge weight = coefficient value)\n",
    "\n",
    "We track how this network topology shifts during geopolitical events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "network-build",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bipartite_graph(edges_df_sub: pd.DataFrame) -> nx.DiGraph:\n",
    "    \"\"\"Build a weighted bipartite DiGraph from an edge subset.\"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(edges_df_sub['feature'].unique(), bipartite='commodity')\n",
    "    G.add_nodes_from(edges_df_sub['stock'].unique(),   bipartite='stock')\n",
    "    for _, row in edges_df_sub.iterrows():\n",
    "        G.add_edge(row['feature'], row['stock'], weight=row['coef'])\n",
    "    return G\n",
    "\n",
    "\n",
    "def plot_bipartite(G: nx.DiGraph, title: str, ax=None):\n",
    "    \"\"\"Draw bipartite graph: commodity features on left, stocks on right.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "    comm_nodes  = [n for n, d in G.nodes(data=True) if d.get('bipartite') == 'commodity']\n",
    "    stock_nodes = [n for n, d in G.nodes(data=True) if d.get('bipartite') == 'stock']\n",
    "\n",
    "    # Layout: two columns\n",
    "    pos = {}\n",
    "    for i, n in enumerate(sorted(comm_nodes)):\n",
    "        pos[n] = (0, -(i / max(len(comm_nodes)-1, 1)))\n",
    "    for i, n in enumerate(sorted(stock_nodes)):\n",
    "        pos[n] = (1, -(i / max(len(stock_nodes)-1, 1)))\n",
    "\n",
    "    weights  = [abs(G[u][v]['weight']) * 800 for u, v in G.edges()]\n",
    "    colors_e = ['green' if G[u][v]['weight'] > 0 else 'crimson' for u, v in G.edges()]\n",
    "\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=comm_nodes,  node_color='steelblue',\n",
    "                           node_size=300, ax=ax)\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=stock_nodes, node_color='darkorange',\n",
    "                           node_size=200, ax=ax)\n",
    "    nx.draw_networkx_edges(G, pos, edge_color=colors_e, width=[w/200 for w in weights],\n",
    "                           alpha=0.5, ax=ax, arrows=True,\n",
    "                           arrowstyle='-|>', arrowsize=10)\n",
    "    nx.draw_networkx_labels(G, pos, {n: n for n in comm_nodes},\n",
    "                            font_size=8, ax=ax, horizontalalignment='right')\n",
    "    nx.draw_networkx_labels(G, pos, {n: n for n in stock_nodes},\n",
    "                            font_size=7, ax=ax, horizontalalignment='left')\n",
    "    ax.set_title(title, fontweight='bold', fontsize=11)\n",
    "    ax.axis('off')\n",
    "\n",
    "\n",
    "if edges_list:\n",
    "    edges_df = pd.DataFrame(edges_list, columns=['date','feature','stock','coef'])\n",
    "\n",
    "    # Network density over time\n",
    "    density_ts = edges_df.groupby('date').size()\n",
    "    density_ts.index = pd.DatetimeIndex(density_ts.index)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(16, 4))\n",
    "    density_ts.rolling(13).mean().plot(ax=ax, color='purple', linewidth=1.5)\n",
    "    ax.fill_between(density_ts.index,\n",
    "                    density_ts.rolling(13).mean(), alpha=0.15, color='purple')\n",
    "    ax.set_ylabel('Number of active edges (13-wk MA)')\n",
    "    ax.set_title('Bipartite Network Density over Time  (# non-zero Lasso edges)',\n",
    "                 fontweight='bold')\n",
    "    for label, date in {'Libya 2011':'2011-02-17', 'OPEC 2014':'2014-11-27',\n",
    "                         'COVID 2020':'2020-03-09', 'Ukraine 2022':'2022-02-24'}.items():\n",
    "        dt = pd.Timestamp(date)\n",
    "        ax.axvline(dt, color='red', linestyle=':', linewidth=1.2, alpha=0.8)\n",
    "        ax.text(dt, ax.get_ylim()[1]*0.95, label, rotation=90,\n",
    "                fontsize=8, color='red', va='top')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "network-snapshot",
   "metadata": {},
   "outputs": [],
   "source": [
    "if edges_list:\n",
    "    # ── Network snapshots: calm vs. crisis ───────────────────────────────────\n",
    "    windows = [\n",
    "        ('Calm 2013',         '2013-01-01', '2013-12-31'),\n",
    "        ('OPEC crisis 2015',  '2015-01-01', '2015-12-31'),\n",
    "        ('COVID 2020',        '2020-01-01', '2020-12-31'),\n",
    "        ('Ukraine 2022',      '2022-02-01', '2022-12-31'),\n",
    "    ]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(22, 11))\n",
    "\n",
    "    for ax, (label, s, e) in zip(axes, windows):\n",
    "        sub = edges_df[\n",
    "            (edges_df['date'] >= pd.Timestamp(s)) &\n",
    "            (edges_df['date'] <= pd.Timestamp(e))\n",
    "        ].copy()\n",
    "\n",
    "        # Aggregate: mean coefficient per (feature, stock) over the window\n",
    "        agg = sub.groupby(['feature','stock'])['coef'].mean().reset_index()\n",
    "        # Keep only the most active stock connections\n",
    "        top_stocks = agg.groupby('stock')['coef'].abs().sum().nlargest(15).index\n",
    "        agg = agg[agg['stock'].isin(top_stocks)]\n",
    "\n",
    "        G = build_bipartite_graph(agg)\n",
    "        n_edges = G.number_of_edges()\n",
    "        plot_bipartite(G, f'{label}\\n({n_edges} edges, top-15 stocks)', ax=ax)\n",
    "\n",
    "    plt.suptitle('Bipartite Network Snapshots — Calm vs. Geopolitical Crisis',\n",
    "                 fontsize=14, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacency-heatmap",
   "metadata": {},
   "outputs": [],
   "source": [
    "if edges_list:\n",
    "    # ── Adjacency heatmap for the most recent 252-day window ─────────────────\n",
    "    recent_edges = edges_df[edges_df['date'] >= edges_df['date'].max() - pd.Timedelta(days=365)]\n",
    "    pivot = recent_edges.pivot_table(\n",
    "        index='feature', columns='stock', values='coef',\n",
    "        aggfunc='mean', fill_value=0\n",
    "    )\n",
    "\n",
    "    # Show top-30 stocks by total absolute weight\n",
    "    top_stocks = pivot.abs().sum(axis=0).nlargest(30).index\n",
    "    pivot_sub  = pivot[top_stocks]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(18, 8))\n",
    "    sns.heatmap(pivot_sub, cmap='RdBu_r', center=0,\n",
    "                linewidths=0.3, linecolor='lightgray',\n",
    "                cbar_kws={'label': 'Mean Lasso coefficient'},\n",
    "                ax=ax)\n",
    "    ax.set_title('Bipartite Adjacency Matrix — most recent year\\n'\n",
    "                 '(rows = commodity features, cols = energy stocks)',\n",
    "                 fontweight='bold', fontsize=12)\n",
    "    ax.set_xlabel('Energy stocks (top 30 by connection strength)')\n",
    "    ax.set_ylabel('Commodity features')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-s7",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 7 — Backtest: Long-Short Strategy\n",
    "\n",
    "**Strategy**:\n",
    "- Each Friday: rank stocks by predicted return\n",
    "- Long top 25% (highest predicted), short bottom 25% (lowest)\n",
    "- Hold until next Friday (weekly rebalancing)\n",
    "- 5 bps one-way transaction cost on weight changes\n",
    "- PnL on **raw returns** (what you actually earn holding the stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backtest-fn",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ls_backtest(\n",
    "    predictions: pd.DataFrame,\n",
    "    raw_returns: pd.DataFrame,\n",
    "    top_pct: float = 0.25,\n",
    "    tc: float = 0.0005,\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Long-short cross-sectional backtest.\n",
    "\n",
    "    - Equal-weight within long and short book\n",
    "    - Forward-fill weights between prediction dates (hold position)\n",
    "    - TC charged only on rebalance days\n",
    "    \"\"\"\n",
    "    pred_days = predictions.index[predictions.notna().any(axis=1)]\n",
    "\n",
    "    weights_sparse = pd.DataFrame(0.0, index=predictions.index, columns=predictions.columns)\n",
    "\n",
    "    for date in pred_days:\n",
    "        row = predictions.loc[date].dropna()\n",
    "        if len(row) < 4:\n",
    "            continue\n",
    "        n        = len(row)\n",
    "        n_long   = max(1, int(n * top_pct))\n",
    "        n_short  = max(1, int(n * top_pct))\n",
    "        ranked   = row.sort_values()\n",
    "        shorts   = ranked.head(n_short).index\n",
    "        longs    = ranked.tail(n_long).index\n",
    "        weights_sparse.loc[date, longs]  =  1.0 / n_long\n",
    "        weights_sparse.loc[date, shorts] = -1.0 / n_short\n",
    "\n",
    "    # Forward-fill (hold position between rebalances)\n",
    "    active = weights_sparse.abs().sum(axis=1) > 0\n",
    "    w_ff   = weights_sparse.where(active, other=np.nan).ffill().fillna(0.0)\n",
    "\n",
    "    ret_aligned = raw_returns.reindex(\n",
    "        index=w_ff.index, columns=w_ff.columns).fillna(0.0)\n",
    "\n",
    "    port_ret = (w_ff * ret_aligned).sum(axis=1)\n",
    "    tc_cost  = weights_sparse.diff().abs().sum(axis=1) * tc\n",
    "    port_ret = port_ret - tc_cost\n",
    "\n",
    "    return port_ret.loc[pred_days[0]:]\n",
    "\n",
    "\n",
    "# ── Run main backtest ─────────────────────────────────────────────────────────\n",
    "ret_main = run_ls_backtest(preds_252, Y_raw_liq, top_pct=0.25, tc=0.0005)\n",
    "\n",
    "oos_start      = ret_main.dropna().index[0]\n",
    "ret_bench_ew   = Y_raw_liq.mean(axis=1)\n",
    "ret_bench_spy  = spy_ret\n",
    "\n",
    "print(f'OOS period: {oos_start.date()} → {ret_main.index[-1].date()}')\n",
    "print(f'Strategy trading days: {ret_main.notna().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backtest-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Performance table ─────────────────────────────────────────────────────────\n",
    "strategies = {\n",
    "    'HAR-Lasso L/S (LassoCV)': ret_main,\n",
    "    'Benchmark: EW Energy':    ret_bench_ew,\n",
    "    'Benchmark: SPY':          ret_bench_spy,\n",
    "}\n",
    "\n",
    "perf = pd.DataFrame({\n",
    "    name: compute_metrics(ret, start=oos_start)\n",
    "    for name, ret in strategies.items()\n",
    "}).T\n",
    "\n",
    "print('\\n' + '=' * 70)\n",
    "print('PERFORMANCE  (OOS period)')\n",
    "print(f'Start: {oos_start.date()}  |  End: {ret_main.index[-1].date()}')\n",
    "print('=' * 70)\n",
    "print(perf.to_string())\n",
    "print('=' * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backtest-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Cumulative returns + drawdown + rolling Sharpe ────────────────────────────\n",
    "fig, axes = plt.subplots(3, 1, figsize=(16, 13), sharex=True,\n",
    "                          gridspec_kw={'height_ratios': [3, 1.5, 1.5]})\n",
    "\n",
    "palette = {'HAR-Lasso L/S (LassoCV)': ('royalblue', 2.2, '-'),\n",
    "           'Benchmark: EW Energy':    ('gray',      1.2, '--'),\n",
    "           'Benchmark: SPY':          ('black',     1.2, ':')}\n",
    "\n",
    "# Panel 1: cumulative\n",
    "ax = axes[0]\n",
    "for name, ret in strategies.items():\n",
    "    c, lw, ls = palette[name]\n",
    "    cum = (1 + ret.loc[oos_start:].fillna(0)).cumprod()\n",
    "    ax.plot(cum, color=c, linewidth=lw, linestyle=ls, label=name)\n",
    "ax.axhline(1, color='black', linewidth=0.5, linestyle='--')\n",
    "ax.set_ylabel('Growth of $1')\n",
    "ax.set_title('HAR-Lasso Bipartite Strategy — Out-of-Sample Performance',\n",
    "             fontsize=13, fontweight='bold')\n",
    "ax.legend()\n",
    "for dt in ['2011-02-17','2014-11-27','2020-03-09','2022-02-24']:\n",
    "    ax.axvline(pd.Timestamp(dt), color='red', linestyle=':', linewidth=1, alpha=0.5)\n",
    "\n",
    "# Panel 2: drawdown\n",
    "ax = axes[1]\n",
    "for name, ret in strategies.items():\n",
    "    c, lw, ls = palette[name]\n",
    "    r   = ret.loc[oos_start:].fillna(0)\n",
    "    cum = (1 + r).cumprod()\n",
    "    dd  = (cum - cum.cummax()) / cum.cummax()\n",
    "    ax.fill_between(dd.index, dd, 0, color=c, alpha=0.25, label=name)\n",
    "ax.set_ylabel('Drawdown')\n",
    "ax.set_title('Drawdowns', fontsize=11)\n",
    "ax.legend(fontsize=9)\n",
    "\n",
    "# Panel 3: rolling Sharpe\n",
    "ax = axes[2]\n",
    "for name, ret in strategies.items():\n",
    "    c, lw, ls = palette[name]\n",
    "    sr = rolling_sharpe(ret.loc[oos_start:], window=252)\n",
    "    ax.plot(sr, color=c, linewidth=lw, linestyle=ls, label=name)\n",
    "ax.axhline(0,  color='black', linewidth=0.5, linestyle='--')\n",
    "ax.axhline( 1, color='green', linewidth=0.7, linestyle=':')\n",
    "ax.axhline(-1, color='red',   linewidth=0.7, linestyle=':')\n",
    "ax.set_ylim(-3.5, 3.5)\n",
    "ax.set_ylabel('Rolling Sharpe (252d)')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_title('Rolling 1-Year Sharpe', fontsize=11)\n",
    "ax.legend(fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUTS / 'backtest_main.png', dpi=120, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-s8",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 8 — Sensitivity: Window Length & Target\n",
    "\n",
    "Per the proposal: *\"study how the Lasso penalty and training window affect edge stability\"*.\n",
    "\n",
    "We test:\n",
    "1. **Window**: 60d (responsive to shocks) vs 252d (stable estimation)\n",
    "2. **Target**: `Y_idio` (residualized) vs `Y_raw` (raw returns)\n",
    "\n",
    "> Hypothesis: shorter window captures faster-decaying geopolitical alpha;\n",
    "> Y_raw may outperform if commodity-beta is itself predictable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 60-day window ─────────────────────────────────────────────────────────────\n",
    "print('Running 60-day window (Y_idio)...')\n",
    "result_60 = rolling_lasso_cv(X, Y_idio_liq, train_window=60, weekly=True, min_obs=30)\n",
    "ret_60_idio = run_ls_backtest(result_60['predictions'], Y_raw_liq)\n",
    "\n",
    "# ── 60-day window on Y_raw ─────────────────────────────────────────────────\n",
    "print('Running 60-day window (Y_raw)...')\n",
    "result_60_raw = rolling_lasso_cv(X, Y_raw_liq, train_window=60, weekly=True, min_obs=30)\n",
    "ret_60_raw = run_ls_backtest(result_60_raw['predictions'], Y_raw_liq)\n",
    "\n",
    "# ── 252-day window on Y_raw ────────────────────────────────────────────────\n",
    "print('Running 252-day window (Y_raw)...')\n",
    "result_252_raw = rolling_lasso_cv(X, Y_raw_liq, train_window=252, weekly=True)\n",
    "ret_252_raw = run_ls_backtest(result_252_raw['predictions'], Y_raw_liq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitivity-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_all = max(\n",
    "    ret_main.dropna().index[0],\n",
    "    ret_60_idio.dropna().index[0] if ret_60_idio.notna().any() else ret_main.dropna().index[0],\n",
    "    ret_60_raw.dropna().index[0]  if ret_60_raw.notna().any()  else ret_main.dropna().index[0],\n",
    "    ret_252_raw.dropna().index[0] if ret_252_raw.notna().any() else ret_main.dropna().index[0],\n",
    ")\n",
    "\n",
    "variants = {\n",
    "    '252d window / Y_idio (main)': ret_main,\n",
    "    '252d window / Y_raw':         ret_252_raw,\n",
    "    ' 60d window / Y_idio':        ret_60_idio,\n",
    "    ' 60d window / Y_raw':         ret_60_raw,\n",
    "    'Benchmark: EW Energy':        ret_bench_ew,\n",
    "    'Benchmark: SPY':               ret_bench_spy,\n",
    "}\n",
    "\n",
    "sens_table = pd.DataFrame({\n",
    "    k: compute_metrics(v, start=oos_all) for k, v in variants.items()\n",
    "}).T\n",
    "\n",
    "print('\\n' + '=' * 72)\n",
    "print('SENSITIVITY: Window Length × Target')\n",
    "print('=' * 72)\n",
    "print(sens_table.to_string())\n",
    "print('=' * 72)\n",
    "\n",
    "# Cumulative chart\n",
    "colors_s = ['royalblue','dodgerblue','darkorange','orangered','gray','black']\n",
    "styles_s  = ['-','-','--','--',':',':']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "for (name, ret), color, ls in zip(variants.items(), colors_s, styles_s):\n",
    "    cum = (1 + ret.loc[oos_all:].fillna(0)).cumprod()\n",
    "    lw  = 2.0 if 'main' in name or 'Benchmark' in name else 1.3\n",
    "    ax.plot(cum, color=color, linewidth=lw, linestyle=ls, label=name, alpha=0.85)\n",
    "ax.axhline(1, color='black', linewidth=0.5, linestyle='--')\n",
    "ax.set_ylabel('Growth of $1')\n",
    "ax.set_title('Sensitivity: Window Length vs Target  (252d vs 60d, Y_idio vs Y_raw)',\n",
    "             fontweight='bold', fontsize=12)\n",
    "ax.legend(fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-conclusion",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "| Component | Implementation |\n",
    "|---|---|\n",
    "| Data | CRSP energy stocks (via cache) + 4 commodity futures + SPY |\n",
    "| Features | 27 HAR + derived (daily/weekly/monthly lags, crack spread, RV, Brent-WTI spread) |\n",
    "| Residualization | Rolling 252-day OLS beta vs SPY → Y_idio |\n",
    "| Model | LassoCV with TimeSeriesSplit(n_splits=3) — dynamic alpha per window |\n",
    "| Rebalancing | Weekly (Fridays) — reduces TC ~5× vs daily |\n",
    "| Portfolio | Long top 25%, short bottom 25% by predicted return |\n",
    "| TC | 5 bps one-way on weight changes |\n",
    "| Bipartite graph | Non-zero Lasso coefficients = edges; tracked over time |\n",
    "\n",
    "**Continue to:**\n",
    "- `02_case_study.ipynb` — geopolitical event analysis and network topology shifts\n",
    "- `03_math_walkthrough.ipynb` — full mathematical architecture with visual derivations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {"name": "python", "version": "3.12.0"}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
